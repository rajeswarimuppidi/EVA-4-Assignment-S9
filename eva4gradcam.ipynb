{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eva4gradcam.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhZ21TU46QTKsud7/f7RGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeswarimuppidi/EVA-4-Assignment-S9/blob/master/eva4gradcam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PugXLZbhXQxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn import functional as F\n",
        "import cv2\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class GradCAM:\n",
        "    \"\"\" Class for extracting activations and \n",
        "    registering gradients from targetted intermediate layers \n",
        "    target_layers = list of convolution layer index as shown in summary\n",
        "    \"\"\"\n",
        "    def __init__(self, model, candidate_layers=None):\n",
        "        def save_fmaps(key):\n",
        "          def forward_hook(module, input, output):\n",
        "              self.fmap_pool[key] = output.detach()\n",
        "\n",
        "          return forward_hook\n",
        "\n",
        "        def save_grads(key):\n",
        "          def backward_hook(module, grad_in, grad_out):\n",
        "              self.grad_pool[key] = grad_out[0].detach()\n",
        "\n",
        "          return backward_hook\n",
        "\n",
        "        self.device = next(model.parameters()).device\n",
        "        self.model = model\n",
        "        self.handlers = []  # a set of hook function handlers\n",
        "        self.fmap_pool = {}\n",
        "        self.grad_pool = {}\n",
        "        self.candidate_layers = candidate_layers  # list\n",
        "\n",
        "        for name, module in self.model.named_modules():\n",
        "            if self.candidate_layers is None or name in self.candidate_layers:\n",
        "                self.handlers.append(module.register_forward_hook(save_fmaps(name)))\n",
        "                self.handlers.append(module.register_backward_hook(save_grads(name)))\n",
        "\n",
        "    def _encode_one_hot(self, ids):\n",
        "        one_hot = torch.zeros_like(self.nll).to(self.device)\n",
        "        print(one_hot.shape)\n",
        "        one_hot.scatter_(1, ids, 1.0)\n",
        "        return one_hot\n",
        "\n",
        "    def forward(self, image):\n",
        "        self.image_shape = image.shape[2:] # HxW\n",
        "        self.nll = self.model(image)\n",
        "        #self.probs = F.softmax(self.logits, dim=1)\n",
        "        return self.nll.sort(dim=1, descending=True)  # ordered results\n",
        "\n",
        "    def backward(self, ids):\n",
        "        \"\"\"\n",
        "        Class-specific backpropagation\n",
        "        \"\"\"\n",
        "        one_hot = self._encode_one_hot(ids)\n",
        "        self.model.zero_grad()\n",
        "        self.nll.backward(gradient=one_hot, retain_graph=True)\n",
        "\n",
        "    def remove_hook(self):\n",
        "        \"\"\"\n",
        "        Remove all the forward/backward hook functions\n",
        "        \"\"\"\n",
        "        for handle in self.handlers:\n",
        "            handle.remove()\n",
        "\n",
        "    def _find(self, pool, target_layer):\n",
        "        if target_layer in pool.keys():\n",
        "            return pool[target_layer]\n",
        "        else:\n",
        "            raise ValueError(\"Invalid layer name: {}\".format(target_layer))\n",
        "\n",
        "    def generate(self, target_layer):\n",
        "        fmaps = self._find(self.fmap_pool, target_layer)\n",
        "        grads = self._find(self.grad_pool, target_layer)\n",
        "        weights = F.adaptive_avg_pool2d(grads, 1)\n",
        "\n",
        "        gcam = torch.mul(fmaps, weights).sum(dim=1, keepdim=True)\n",
        "        gcam = F.relu(gcam)\n",
        "        # need to capture image size duign forward pass\n",
        "        gcam = F.interpolate(\n",
        "            gcam, self.image_shape, mode=\"bilinear\", align_corners=False\n",
        "        )\n",
        "\n",
        "        # scale output between 0,1\n",
        "        B, C, H, W = gcam.shape\n",
        "        gcam = gcam.view(B, -1)\n",
        "        gcam -= gcam.min(dim=1, keepdim=True)[0]\n",
        "        gcam /= gcam.max(dim=1, keepdim=True)[0]\n",
        "        gcam = gcam.view(B, C, H, W)\n",
        "\n",
        "        return gcam\n",
        "\n",
        "def GRADCAM(images, labels, model, target_layers):\n",
        "  model.eval()\n",
        "  # map input to device\n",
        "  images = torch.stack(images).to(model.device)\n",
        "  # set up grad cam\n",
        "  gcam = GradCAM(model, target_layers)\n",
        "  # forward pass\n",
        "  probs, ids = gcam.forward(images)\n",
        "  # outputs agaist which to compute gradients\n",
        "  ids_ = torch.LongTensor(labels).view(len(images),-1).to(model.device)\n",
        "  # backward pass\n",
        "  gcam.backward(ids=ids_)\n",
        "  layers = []\n",
        "  for i in range(len(target_layers)):\n",
        "    target_layer = target_layers[i]\n",
        "    print(\"Generating Grad-CAM @{}\".format(target_layer))\n",
        "    # Grad-CAM\n",
        "    layers.append(gcam.generate(target_layer=target_layer))\n",
        "  # remove hooks when done\n",
        "  gcam.remove_hook()\n",
        "  return layers, probs, ids\n",
        "\n",
        "def PLOT(gcam_layers, images, labels, target_layers, class_names, image_size, predicted, unnormalize):\n",
        "    c = len(images)+1\n",
        "    r = len(target_layers)+2\n",
        "    fig = plt.figure(figsize=(32,14))\n",
        "    fig.subplots_adjust(hspace=0.01, wspace=0.01)\n",
        "    ax = plt.subplot(r, c, 1)\n",
        "    ax.text(0.3,-0.5, \"INPUT\", fontsize=14)\n",
        "    plt.axis('off')\n",
        "    for i in range(len(target_layers)):\n",
        "      target_layer = target_layers[i]\n",
        "      ax = plt.subplot(r, c, c*(i+1)+1)\n",
        "      ax.text(0.3,-0.5, target_layer, fontsize=14)\n",
        "      plt.axis('off')\n",
        "\n",
        "      for j in range(len(images)):\n",
        "        img = np.uint8(255*unnormalize(images[j].view(image_size)))\n",
        "        if i==0:\n",
        "          ax = plt.subplot(r, c, j+2)\n",
        "          ax.text(0, 0.2, f\"pred={class_names[predicted[j][0]]}\\n[actual={class_names[labels[j]]}]\", fontsize=14)\n",
        "          plt.axis('off')\n",
        "          plt.subplot(r, c, c+j+2)\n",
        "          plt.imshow(img, interpolation='bilinear')\n",
        "          plt.axis('off')\n",
        "\n",
        "\n",
        "        heatmap = 1-gcam_layers[i][j].cpu().numpy()[0] # reverse the color map\n",
        "        heatmap = np.uint8(255 * heatmap)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "        superimposed_img = cv2.resize(cv2.addWeighted(img, 0.5, heatmap, 0.5, 0), (128,128))\n",
        "        plt.subplot(r, c, (i+2)*c+j+2)\n",
        "        plt.imshow(superimposed_img, interpolation='bilinear')\n",
        "\n",
        "        plt.axis('off')\n",
        "    plt.show() \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRe-0nT1XV1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}